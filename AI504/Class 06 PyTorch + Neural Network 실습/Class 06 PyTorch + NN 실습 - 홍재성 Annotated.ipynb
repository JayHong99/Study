{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: PyTorch, Logistic Regression and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
    "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
    "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
    "\n",
    "If you have any questions, feel free to ask\n",
    "- For additional questions, post questions in classum or send emails to jihoontack@kaist.ac.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intuitive and concise code\n",
    "- Define by Run method (Tensorflow is Define and Run method)\n",
    "- High compatibility with Numpy (almost one-to-one mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prelim: Load packages & GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  4 23:32:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.72       Driver Version: 461.72       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3070   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   49C    P2    55W / 270W |   1791MiB /  8192MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1664    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8660    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     11552    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     15344    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15612    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     16496    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     16768    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     17784    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     20700    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     21408    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     22792    C+G   ...rograms\\Notion\\Notion.exe    N/A      |\n",
      "|    0   N/A  N/A     22880    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     23376    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     24200    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24504      C   ...Data\\Anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# visualize current GPU usages in your server\n",
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu by number \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1\n"
     ]
    }
   ],
   "source": [
    "# print the version of PyTorch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
    "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
    "**Almost the same with Numpy array**\n",
    "\n",
    "- 파이토치와 Numpy는 굉장히 유사함\n",
    "- Numpy의 구조를 거의 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch and Numpy shares almost identical grammer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**We will show some examples of:**\n",
    "- Same operation with identical grammer\n",
    "- Same operation with different grammer\n",
    "- Different operation with same grammer\n",
    "\n",
    "**We will not handle all examples in this class :(**\n",
    "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users\n",
    "- 위 링크에서 차이점을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First! Define Numpy array and PyTorch tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[5 6 7 8]\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "np_array_1 = np.array([1, 2, 3, 4])\n",
    "np_array_2 = np.array([5, 6, 7, 8])\n",
    "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
    "\n",
    "print (np_array_1)\n",
    "print (np_array_2)\n",
    "print (torch_tensor_1)\n",
    "print (torch_tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Same operations with identical grammer**\n",
    "\n",
    "Example) Get the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "print (np_array_1.shape)\n",
    "\n",
    "# torch\n",
    "print (torch_tensor_1.shape)\n",
    "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Same operations with different grammer**\n",
    "\n",
    "Example 1) Concatenate two tensors\n",
    "- numpy use `np.concatenate`\n",
    "- torch use `torch.cat`\n",
    "- IMPORTANT: axis (numpy) and dim (torch) is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----numpy----\n",
      "[1 2 3 4 5 6 7 8]\n",
      "----torch----\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
    "print ('----numpy----')\n",
    "print (np_concate)\n",
    "\n",
    "# torch\n",
    "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
    "print ('----torch----')\n",
    "print (torch_concate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2) reshape the tensor shape\n",
    "- numpy use `X.reshape`\n",
    "- torch use `X.view`\n",
    "- IMPORTANT: axis (numpy) and dim (torch) is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----numpy----\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "(4, 2)\n",
      "----torch----\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "np_reshaped = np_concate.reshape(4, 2)\n",
    "print ('----numpy----')\n",
    "print (np_reshaped)\n",
    "print (np_reshaped.shape)\n",
    "\n",
    "# torch\n",
    "torch_reshaped = torch_concate.view(4, 2)\n",
    "print ('----torch----')\n",
    "print (torch_reshaped)\n",
    "print (torch_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Different operations with same grammer (Confusing operations)**\n",
    "\n",
    "Example) manipulation tensors\n",
    "- Same grammer `repeat`  has different operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----numpy----\n",
      "[1 2 3]\n",
      "[1 1 2 2 3 3]\n",
      "----torch----\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3, 1, 2, 3])\n",
      "tensor([1, 1, 2, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "x_repeat = x.repeat(2)\n",
    "\n",
    "print ('----numpy----')\n",
    "print (x)\n",
    "print (x_repeat)\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_repeat = x.repeat(2)\n",
    "\n",
    "print ('----torch----')\n",
    "print (x)\n",
    "print (x_repeat)\n",
    "\n",
    "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
    "x_repeat = x.view(3, 1).repeat(1, 2).view(-1)\n",
    "print (x_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "# similar manipulation operation: stack & repeat\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x_repeat = x.repeat(4)\n",
    "x_stack = torch.stack([x, x, x, x])\n",
    "\n",
    "print (x_repeat)\n",
    "print (x_stack)\n",
    "print (x_repeat.view(4, 3)) # reshape x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor operations under GPU utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning frameworks utilize GPUs to accelarate computations.\n",
    "\n",
    "In this section, we will learn **how to utilize GPU** in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Is GPU accessible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3)\n",
    "b = torch.randn(100, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload a and b to GPU\n",
    "a = a.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to all neural networks in PyTorch is the `autograd` package. \n",
    "\n",
    "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
    "\n",
    "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.retain_grad()\n",
    "z.retain_grad()\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- out = 1/4 mean of z\n",
    "- partial out / partial z = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z_i = 3*y^2\n",
    "- partial out/ partialz * partialz/partial y = 1/4 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y = x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient inference (testing) with torch.no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
    "\n",
    "Situation: when **gradient calculation is not required** e.g., inference\\\n",
    "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.ones(2, 2, requires_grad=True)\n",
    "    y = x + 2\n",
    "    z = y * y * 3\n",
    "    out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-bf3332dd1f01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-defined modules (subset of models) in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "\n",
    "print (X)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim 3, output dim 1\n",
    "linear_fn = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=1, bias=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_fn  # WX + b # W와 b는 시작할 때 random한 값으로 설정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7911],\n",
      "        [-0.4613]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "Y = linear_fn(X)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2524, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.sum()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use other types of `nn.Module` in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d\n",
    "nn.RNNCell\n",
    "nn.LSTMCell\n",
    "nn.GRUCell\n",
    "nn.Transformer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we design a customized model (neural network)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x) # Activation function\n",
    "        x = self.linear_2(x)\n",
    "        return x # 위의 forward를 계산해서 return 해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is activation function?**\n",
    "- They make non-linearity for deep neural networks\n",
    "- Therefore, deep neural networks can approximate complex functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sigmoid\n",
    "nn.ReLU\n",
    "nn.LeakyReLU\n",
    "nn.Tanh;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is MNIST & How to do multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    "\n",
    "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
    "\n",
    "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor()) \n",
    "\n",
    "# Data loader\n",
    "# mini batch size\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True) # 학습은 random하게 학습하려고 함\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False) # Test는 단순하게 예측용이니 변환 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model (we will use one layer classifier first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1Xe4J88NglbuASnfYJYI7ISqA1c1rcs5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "# This model has one hidden layer\n",
    "class Multinomial_logistic_regression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Multinomial_logistic_regression, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "model = Multinomial_logistic_regression(784, 10)  # init(784, 10) # 784 = 28*28\n",
    "# input dim: 784  / output dim: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multinomial_logistic_regression(\n",
       "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to GPU\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
    "\n",
    "PyTorch optimizer is about **which optimization methods to use for training**\n",
    "\n",
    "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer define\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9) # Learning rate는 domain 적인 지식이다.\n",
    "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/469], Loss: 0.3859\n",
      "Epoch [1/10], Step [200/469], Loss: 0.3100\n",
      "Epoch [1/10], Step [300/469], Loss: 0.2973\n",
      "Epoch [1/10], Step [400/469], Loss: 0.4189\n",
      "Epoch [2/10], Step [100/469], Loss: 0.2191\n",
      "Epoch [2/10], Step [200/469], Loss: 0.4047\n",
      "Epoch [2/10], Step [300/469], Loss: 0.2631\n",
      "Epoch [2/10], Step [400/469], Loss: 0.2824\n",
      "Epoch [3/10], Step [100/469], Loss: 0.3536\n",
      "Epoch [3/10], Step [200/469], Loss: 0.3200\n",
      "Epoch [3/10], Step [300/469], Loss: 0.2739\n",
      "Epoch [3/10], Step [400/469], Loss: 0.1914\n",
      "Epoch [4/10], Step [100/469], Loss: 0.3158\n",
      "Epoch [4/10], Step [200/469], Loss: 0.4244\n",
      "Epoch [4/10], Step [300/469], Loss: 0.2944\n",
      "Epoch [4/10], Step [400/469], Loss: 0.2788\n",
      "Epoch [5/10], Step [100/469], Loss: 0.2501\n",
      "Epoch [5/10], Step [200/469], Loss: 0.2478\n",
      "Epoch [5/10], Step [300/469], Loss: 0.2207\n",
      "Epoch [5/10], Step [400/469], Loss: 0.4324\n",
      "Epoch [6/10], Step [100/469], Loss: 0.2654\n",
      "Epoch [6/10], Step [200/469], Loss: 0.2374\n",
      "Epoch [6/10], Step [300/469], Loss: 0.3502\n",
      "Epoch [6/10], Step [400/469], Loss: 0.1904\n",
      "Epoch [7/10], Step [100/469], Loss: 0.2390\n",
      "Epoch [7/10], Step [200/469], Loss: 0.2169\n",
      "Epoch [7/10], Step [300/469], Loss: 0.3039\n",
      "Epoch [7/10], Step [400/469], Loss: 0.2141\n",
      "Epoch [8/10], Step [100/469], Loss: 0.3622\n",
      "Epoch [8/10], Step [200/469], Loss: 0.2062\n",
      "Epoch [8/10], Step [300/469], Loss: 0.2768\n",
      "Epoch [8/10], Step [400/469], Loss: 0.1600\n",
      "Epoch [9/10], Step [100/469], Loss: 0.2866\n",
      "Epoch [9/10], Step [200/469], Loss: 0.2004\n",
      "Epoch [9/10], Step [300/469], Loss: 0.2998\n",
      "Epoch [9/10], Step [400/469], Loss: 0.2369\n",
      "Epoch [10/10], Step [100/469], Loss: 0.2671\n",
      "Epoch [10/10], Step [200/469], Loss: 0.1967\n",
      "Epoch [10/10], Step [300/469], Loss: 0.2264\n",
      "Epoch [10/10], Step [400/469], Loss: 0.1145\n"
     ]
    }
   ],
   "source": [
    "# Loss function define (we use cross-entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
    "        # upload to gpu\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # forwardI(images): get prediction\n",
    "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
    "        \n",
    "        ## loss.backward() : Cahine Rule을 이용해서 미분 값을 계산하는 과정\n",
    "        ## optimizer.step() : loss.backward()를 통해 계산한 값을 이용해 기존의 파라미터를 업데이트 하는 과정\n",
    "        ## optimizer.zero_grad() : \n",
    "\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()  # automatic gradient calculation (autograd)\n",
    "        optimizer.step()  # update model parameter with requires_grad=True \n",
    "        optimizer.zero_grad() # step에서 학습한 gradient를 초기화\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 92.56 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2534,  1.1049,  2.7277,  1.2657, -0.7759,  2.7473, -0.3041, -8.2683,\n",
       "         6.4942, -2.2546], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model: MLP (multi-layer-perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous model used multinomial logistic regression (one linear layer)\\\n",
    "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model with multi layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/469], Loss: 2.2703\n",
      "Epoch [1/10], Step [200/469], Loss: 1.8991\n",
      "Epoch [1/10], Step [300/469], Loss: 1.4574\n",
      "Epoch [1/10], Step [400/469], Loss: 0.9102\n",
      "Epoch [2/10], Step [100/469], Loss: 0.7551\n",
      "Epoch [2/10], Step [200/469], Loss: 0.4483\n",
      "Epoch [2/10], Step [300/469], Loss: 0.4490\n",
      "Epoch [2/10], Step [400/469], Loss: 0.4369\n",
      "Epoch [3/10], Step [100/469], Loss: 0.3848\n",
      "Epoch [3/10], Step [200/469], Loss: 0.4317\n",
      "Epoch [3/10], Step [300/469], Loss: 0.2673\n",
      "Epoch [3/10], Step [400/469], Loss: 0.1803\n",
      "Epoch [4/10], Step [100/469], Loss: 0.2525\n",
      "Epoch [4/10], Step [200/469], Loss: 0.2544\n",
      "Epoch [4/10], Step [300/469], Loss: 0.3289\n",
      "Epoch [4/10], Step [400/469], Loss: 0.3812\n",
      "Epoch [5/10], Step [100/469], Loss: 0.1769\n",
      "Epoch [5/10], Step [200/469], Loss: 0.2783\n",
      "Epoch [5/10], Step [300/469], Loss: 0.2870\n",
      "Epoch [5/10], Step [400/469], Loss: 0.1935\n",
      "Epoch [6/10], Step [100/469], Loss: 0.2329\n",
      "Epoch [6/10], Step [200/469], Loss: 0.1272\n",
      "Epoch [6/10], Step [300/469], Loss: 0.2758\n",
      "Epoch [6/10], Step [400/469], Loss: 0.1517\n",
      "Epoch [7/10], Step [100/469], Loss: 0.1595\n",
      "Epoch [7/10], Step [200/469], Loss: 0.1723\n",
      "Epoch [7/10], Step [300/469], Loss: 0.2553\n",
      "Epoch [7/10], Step [400/469], Loss: 0.1035\n",
      "Epoch [8/10], Step [100/469], Loss: 0.0935\n",
      "Epoch [8/10], Step [200/469], Loss: 0.1852\n",
      "Epoch [8/10], Step [300/469], Loss: 0.2377\n",
      "Epoch [8/10], Step [400/469], Loss: 0.1945\n",
      "Epoch [9/10], Step [100/469], Loss: 0.0903\n",
      "Epoch [9/10], Step [200/469], Loss: 0.1195\n",
      "Epoch [9/10], Step [300/469], Loss: 0.0901\n",
      "Epoch [9/10], Step [400/469], Loss: 0.1326\n",
      "Epoch [10/10], Step [100/469], Loss: 0.1767\n",
      "Epoch [10/10], Step [200/469], Loss: 0.1614\n",
      "Epoch [10/10], Step [300/469], Loss: 0.1318\n",
      "Epoch [10/10], Step [400/469], Loss: 0.1265\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
    "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
    "\n",
    "# Upload model to GPU\n",
    "model = model.to('cuda')\n",
    "\n",
    "# Loss function define (we use cross-entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
    "        # upload to gpu\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # forwardI(images): get prediction\n",
    "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # automatic gradient calculation (autograd)\n",
    "        optimizer.step()  # update model parameter with requires_grad=True \n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.41 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the following options to obtain better accuracy!! (try it by your-self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Model configurations: \n",
    "- size of hidden layer units\n",
    "- number of layers\n",
    "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
    "\n",
    "#### (2) Optimization configurations\n",
    "- learning rate\n",
    "- epoch\n",
    "- type of optimizer\n",
    "- momentem hyperparameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
